import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

train_df = pd.read_csv("../../data/raw/train.csv")
test_df = pd.read_csv("../../data/raw/test.csv")

train_df.info()
train_df.head()
train_df.isna().sum()

# ëŒ€ë¶€ë¶„ì´ ê²°ì¸¡ì¹˜ì¸ í–‰ ì œê±°
train_df.drop(19327, inplace=True)

# ë¶„ì„ì—ì„œ í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ ì œê±°
train_df.drop(columns=["id", "line", "name", "mold_name", "emergency_stop", "registration_time"], inplace=True)

# tryshot == "D" í–‰ ì œê±°
train_df = train_df.loc[~(train_df["tryshot_signal"] == "D"), :]
train_df.drop(columns=["tryshot_signal"], inplace=True)

'''
ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (molten_temp)
ë™ì¼ì½”ë“œ ì• ìƒì‚° ì˜¨ë„, ë™ì¼ ì½”ë“œ ë’¤ ìƒì‚° ì˜¨ë„ í‰ê· 
'''
# ğŸ”¹ ì›ë³¸ molten_tempë¥¼ ìƒˆë¡œìš´ ì—´ë¡œ ë³µì‚¬
train_df['molten_temp_filled'] = train_df['molten_temp']

# ğŸ”¹ ê¸ˆí˜•ë³„ ì‹œê°„ ìˆœ ì •ë ¬ í›„ ì„ í˜• ë³´ê°„
train_df['molten_temp_filled'] = (
    train_df.groupby('mold_code')['molten_temp_filled'].transform(lambda x: x.interpolate(method='linear'))
)

# ğŸ”¹ ì—¬ì „íˆ ë‚¨ì•„ìˆëŠ” ê²°ì¸¡ì¹˜(ë§¨ ì•/ë’¤)ëŠ” ê·¸ë£¹ë³„ ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
train_df['molten_temp_filled'] = (
    train_df.groupby('mold_code')['molten_temp_filled'].transform(lambda x: x.fillna(x.median()))
)
train_df[['molten_temp', 'molten_temp_filled']]
train_df['molten_temp'].isna().sum()
train_df['molten_temp_filled'].isna().sum()
train_df.drop(columns=["molten_temp"], inplace=True)

# ìˆ˜ì¹˜í˜• -> ë²”ì£¼í˜•
train_df["mold_code"] = train_df["mold_code"].astype('object')
train_df["EMS_operation_time"] = train_df["EMS_operation_time"].astype("object")

# heating_furnace ê²°ì¸¡ì¹˜ ì²˜ë¦¬
train_df["heating_furnace"].fillna("c", inplace=True)

# date, time dt ë°”ê¾¸ê¸°
train_df['date'] = pd.to_datetime(train_df['date'], format='%H:%M:%S')
train_df['time'] = pd.to_datetime(train_df['time'], format='%Y-%m-%d', errors='coerce')

# ì‹œê°„ ì»¬ëŸ¼ ë§Œë“¤ê¸°
train_df["hour"] = train_df["date"].dt.hour
train_df.drop(columns=["date"], inplace=True)

# ìš”ì¼ ì»¬ëŸ¼ ë§Œë“¤ê¸°
train_df["weekday"] = train_df["time"].dt.weekday
train_df.drop(columns=["time"], inplace=True)

# ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ì»¬ëŸ¼ ì„ íƒ
num_columns = train_df.select_dtypes(include=['number']).columns
num_columns = num_columns.drop("passorfail")
cat_columns = train_df.select_dtypes(include=['object']).columns

# ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (ê°„ë‹¨íˆ ì²˜ë¦¬)
freq_impute = SimpleImputer(strategy='most_frequent')
mean_impute = SimpleImputer(strategy='mean')

train_df[cat_columns] = freq_impute.fit_transform(train_df[cat_columns])
train_df[num_columns] = mean_impute.fit_transform(train_df[num_columns])

# ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§
onehot = OneHotEncoder(handle_unknown='ignore',                        
                       sparse_output=False).set_output(transform="pandas")
std_scaler = StandardScaler().set_output(transform="pandas")

train_df_cat = onehot.fit_transform(train_df[cat_columns])
train_df_num = std_scaler.fit_transform(train_df[num_columns])

train_df_all = pd.concat([train_df_cat,
                          train_df_num], axis = 1)

# X, y ì„¤ì •
X_train = train_df_all
y_train = train_df["passorfail"]

rf = RandomForestClassifier(oob_score=True)

rf.fit(X_train, y_train)

result = pd.DataFrame({
    "columns" : train_df_all.columns,
    "importances" : rf.feature_importances_
})

result.sort_values("importances", ascending=False).head(10)